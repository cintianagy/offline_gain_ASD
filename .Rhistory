select(c("Group", "AQ_total", "Subject", "mean_SL", "offline_SL"))
study2_micro_vs_grand_SL <- merge(study2_stat_learn, study2_SL, by = c("Group", "Subject"))
study2_micro_vs_grand_SL <- study2_micro_vs_grand_SL %>%
select(c("Group", "AQ_total", "Subject", "mean_SL", "offline_SL"))
library(tidyverse)
library(rstatix)
library(readr)
library(dplyr)
library(car)
library(tidyverse)
library(sjPlot)
library(lme4)
library(performance)
library(nortest)
library(lmeresampler)
study1_stat_learn <- read_csv("processed_data/study_1/data_study_1_statistical_learning.csv")
study1_visuomotor_perf  <- read_csv("processed_data/study_1/data_study_1_visuomotor_performance.csv")
study2_stat_learn  <- read_csv("processed_data/study_2/data_study_2_statistical_learning.csv")
study2_visuomotor_perf  <- read_csv("processed_data/study_2/data_study_2_visuomotor_performance.csv")
study1_SL <- read_csv("processed_data/study_1/data_study_1_SL_offline_online.csv")
study1_VP <- read_csv("processed_data/study_1/data_study_1_VP_offline_online.csv")
study2_SL <- read_csv("processed_data/study_2/data_study_2_SL_offline_online.csv")
study2_VP <- read_csv("processed_data/study_2/data_study_2_VP_offline_online.csv")
study1_micro_vs_grand_SL <- merge(study1_stat_learn, study1_SL, by = c("Group", "AQ_total", "Subject"))
study1_micro_vs_grand_SL <- study1_micro_vs_grand_SL %>%
select(c("Group", "AQ_total", "Subject", "mean_SL", "offline_SL"))
study1_micro_vs_grand_VP <- merge(study1_visuomotor_perf, study1_VP, by = c("Group", "AQ_total", "Subject"))
study1_micro_vs_grand_VP <- study1_micro_vs_grand_VP %>%
select(c("Group", "AQ_total", "Subject", "mean_VP", "offline_VP"))
study2_micro_vs_grand_SL <- merge(study2_stat_learn, study2_SL, by = c("Group", "Subject"))
study2_micro_vs_grand_SL <- study2_micro_vs_grand_SL %>%
select(c("Group", "AQ_total", "Subject", "mean_SL", "offline_SL"))
study2_micro_vs_grand_SL <- merge(study2_stat_learn, study2_SL, by = c("Group", "Subject"))
study2_micro_vs_grand_SL <- study2_micro_vs_grand_SL %>%
select(c("Group", "Subject", "mean_SL", "offline_SL"))
study2_micro_vs_grand_VP <- merge(study2_visuomotor_perf, study2_VP, by = c("Group", "Subject"))
study2_micro_vs_grand_VP <- study2_micro_vs_grand_VP %>%
select(c("Group", "Subject", "mean_VP", "offline_VP"))
View(study1_micro_vs_grand_SL)
test <- cor.test(study1_micro_vs_grand_SL$mean_SL, study1_micro_vs_grand_SL$offline_SL)
test
cor.test(study1_micro_vs_grand_SL$mean_SL, study1_micro_vs_grand_SL$offline_SL)
cor.test(study1_micro_vs_grand_VP$mean_VP, study1_micro_vs_grand_VP$offline_VP)
cor.test(study1_micro_vs_grand_VP$mean_VP, (study1_micro_vs_grand_VP$offline_VP)*(-1))
cor.test(study2_micro_vs_grand_SL$mean_SL, study2_micro_vs_grand_SL$offline_SL)
cor.test(study2_micro_vs_grand_VP$mean_VP, (study2_micro_vs_grand_VP$offline_VP)*(-1))
cor.test(study1_micro_vs_grand_SL$mean_SL, study1_micro_vs_grand_SL$offline_SL)
cor.test(study1_micro_vs_grand_VP$mean_VP, (study1_micro_vs_grand_VP$offline_VP)*(-1))
rcorr(as.matrix(study1_micro_vs_grand_S[AQ_total, mean_SL, offline_SL]))
library(tidyverse)
library(rstatix)
library(readr)
library(dplyr)
library(car)
library(tidyverse)
library(sjPlot)
library(lme4)
library(performance)
library(nortest)
library(lmeresampler)
library(Hmisc)
rcorr(as.matrix(study1_micro_vs_grand_S[AQ_total, mean_SL, offline_SL]))
rcorr(as.matrix(study1_micro_vs_grand_SL[AQ_total, mean_SL, offline_SL]))
rcorr(as.matrix(study1_micro_vs_grand_SL[[AQ_total, mean_SL, offline_SL]]))
rcorr(as.matrix(select(study1_micro_vs_grand_SL, c('AQ_total', 'mean_SL', 'offline_SL')))
rcorr(as.matrix(select(study1_micro_vs_grand_SL, c('AQ_total', 'mean_SL', 'offline_SL'))))
rcorr(as.matrix(select(study1_micro_vs_grand_VP, c('AQ_total', 'mean_VP', 'offline_VP'))))
study1_micro_vs_grand_SL_lowerAQ <- study1_micro_vs_grand_SL %>%
filter(Group == 0)
cor.test(study1_micro_vs_grand_SL_lowerAQ$mean_SL, study1_micro_vs_grand_SL_lowerAQ$offline_SL)
study1_micro_vs_grand_SL_higherAQ <- study1_micro_vs_grand_SL %>%
filter(Group == 1)
cor.test(study1_micro_vs_grand_SL_higher$mean_SL, study1_micro_vs_grand_SL_higherAQ$offline_SL)
study1_micro_vs_grand_SL_higherAQ <- study1_micro_vs_grand_SL %>%
filter(Group == 1)
cor.test(study1_micro_vs_grand_SL_higherAQ$mean_SL, study1_micro_vs_grand_SL_higherAQ$offline_SL)
study1_micro_vs_grand_VP_lowerAQ <- study1_micro_vs_grand_VP %>%
filter(Group == 0)
cor.test(study1_micro_vs_grand_VP_lowerAQ$mean_VP, study1_micro_vs_grand_VP_lowerAQ$offline_VP)
study1_micro_vs_grand_VP_lowerAQ <- study1_micro_vs_grand_VP %>%
filter(Group == 1)
cor.test(study1_micro_vs_grand_VP_lowerAQ$mean_VP, study1_micro_vs_grand_VP_lowerAQ$offline_VP)
study1_micro_vs_grand_VP_NTP <- study1_micro_vs_grand_VP %>%
filter(Group == 0)
cor.test(study1_micro_vs_grand_VP_NTP$mean_VP, study1_micro_vs_grand_VP_NTP$offline_VP)
study1_micro_vs_grand_VP_NTP <- study1_micro_vs_grand_VP %>%
filter(Group == 1)
cor.test(study1_micro_vs_grand_VP_NTP$mean_VP, study1_micro_vs_grand_VP_NTP$offline_VP)
study2_micro_vs_grand_SL_NTP <- study2_micro_vs_grand_SL %>%
filter(Group == 0)
cor.test(study2_micro_vs_grand_SL_NTP$mean_SL, study2_micro_vs_grand_SL_NTP$offline_SL)
study2_micro_vs_grand_SL_ASD <- study2_micro_vs_grand_SL %>%
filter(Group == 1)
cor.test(study2_micro_vs_grand_SL_ASD$mean_SL, study2_micro_vs_grand_SL_ASD$offline_SL)
library(tidyverse)
library(ggplot2)
library(readxl)
library(psych)
library(plotrix)
library(lcmm)
library(nnet)
library(questionr)
set.seed(500)
study1_SL <- read_csv("processed_data/study_1/data_study_1_SL_offline_online.csv")
study1_VP <- read_csv("processed_data/study_1/data_study_1_VP_offline_online.csv")
study1_SL$ID <- seq.int(nrow(study1_SL))
study1_SL_numeric <- study1_SL %>%
select(c('AQ_total', 'block2_offline','block3_offline', 'block4_offline','block5_offline', 'block6_offline','block7_offline', 'block8_offline','block9_offline', 'block10_offline',
'block11_offline', 'block12_offline','block13_offline', 'block14_offline','block15_offline', 'block16_offline', 'block17_offline','block18_offline', 'block19_offline','block20_offline', 'block21_offline', 'block22_offline','block23_offline', 'block24_offline','block25_offline'))
# test normality
sapply(study1_SL_numeric, shapiro.test)
# make long data
study1_SL_long <- study1_SL %>%
select(c( 'ID', 'Group', 'AQ_total', 'Subject', 'block2_offline','block3_offline', 'block4_offline','block5_offline', 'block6_offline','block7_offline', 'block8_offline','block9_offline', 'block10_offline',
'block11_offline', 'block12_offline','block13_offline', 'block14_offline','block15_offline', 'block16_offline', 'block17_offline','block18_offline', 'block19_offline','block20_offline', 'block21_offline', 'block22_offline','block23_offline', 'block24_offline','block25_offline'))
blocks <- c('block2','block3', 'block4','block5', 'block6','block7', 'block8','block9', 'block10',
'block11', 'block12','block13', 'block14','block15', 'block16', 'block17','block18',
'block19','block20', 'block21', 'block22','block23', 'block24','block25')
study1_SL_long <- pivot_longer(
data = study1_SL_long,
cols = starts_with(blocks),
names_to = c("Block"),
values_to = "SL_score"
)
study1_SL_long <- study1_SL_long %>%
mutate(Block = gsub('_offline', "", Block)) %>%
mutate(Block = gsub('block', "", Block))
study1_SL_long <- study1_SL_long %>%
mutate(Block = as.numeric(Block)) %>%
mutate(Epoch = case_when(
between(Block, 2, 5)   ~ 1,
between(Block, 6, 10)  ~ 2,
between(Block, 11, 15) ~ 3,
between(Block, 16, 20) ~ 4,
between(Block, 21, 25) ~ 5
))
study1_SL_wide <- study1_SL_long %>%
group_by(ID, Subject, Group, AQ_total, Epoch) %>%
summarise(SL_score_epoch = median(SL_score, SL_score, na.rm = T)) %>%
ungroup()
m1.lin <- hlme(SL_score_epoch ~ AQ_total, random = ~AQ_total, subject = 'ID', data = study1_SL_wide)
m2.lin <- gridsearch(hlme(SL_score_epoch ~ AQ_total, random = ~AQ_total, subject = 'ID', data = study1_SL_wide, ng = 2, mixture = ~AQ_total), rep = 200, maxiter = 50, minit = m1.lin)
m3.lin <- gridsearch(hlme(SL_score_epoch ~ AQ_total, random = ~AQ_total, subject = 'ID', data = study1_SL_wide, ng = 3, mixture = ~AQ_total), rep = 200, maxiter = 50, minit = m1.lin)
m1.lin <- hlme(SL_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_SL_wide)
m2.lin <- gridsearch(hlme(SL_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_SL_wide, ng = 2, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
m3.lin <- gridsearch(hlme(SL_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_SL_wide, ng = 3, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
summarytable(m1.lin, m2.lin, m3.lin, which = c("G", "loglik", "conv", "npm", "AIC", "BIC", "SABIC", "entropy", "ICL", "%class"))
summarytable(m1.lin, m2.lin, m3.lin, which = c("G", "loglik", "conv", "npm", "AIC", "BIC", "SABIC", "entropy", "ICL", "%class"))
m4.lin <- gridsearch(hlme(SL_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_SL_wide, ng = 3, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
summarytable(m1.lin, m2.lin, m3.lin, m4.lin, which = c("G", "loglik", "conv", "npm", "AIC", "BIC", "SABIC", "entropy", "ICL", "%class"))
summary(m4.lin)
#post.prob <- postprob(m1.lin)
m4.lin <- gridsearch(hlme(SL_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_SL_wide, ng = 4, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
m5.lin <- gridsearch(hlme(SL_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_SL_wide, ng = 5, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
summarytable(m1.lin, m2.lin, m3.lin, m4.lin, which = c("G", "loglik", "conv", "npm", "AIC", "BIC", "SABIC", "entropy", "ICL", "%class"))
summary(m4.lin)
#post.prob <- postprob(m1.lin)
summary(m5.lin)
#post.prob <- postprob(m1.lin)
summarytable(m1.lin, m2.lin, m3.lin, which = c("G", "loglik", "conv", "npm", "AIC", "BIC", "SABIC", "entropy", "ICL", "%class"))
summary(m1.lin)
#post.prob <- postprob(m1.lin)
summarytable(m1.lin)
#post.prob <- postprob(m1.lin)
?summarytable
library(tidyverse)
library(stats)
library(rstatix)
study1 <- read_delim("processed_data/study_1/data_study_1_general.csv", delim = ';')
study2 <- read_delim("processed_data/study_2/data_study_2_general.csv", delim = ';')
study2_cog_tasks <- read_csv("processed_data/study_2/data_study_2_cognitive_tasks.csv")
study1 <- study1 %>%
mutate(age = as.numeric(age))
study1_lowerAQ <- study1 %>%
filter(Group == 0)
study1_higherAQ <- study1 %>%
filter(Group == 1)
study2 <- study2 %>%
mutate(age = as.numeric(age))
study2_NTP <- study2 %>%
filter(Group == 0)
study2_ASD <- study2 %>%
filter(Group == 1)
study2_cog_NTP <- study2_cog_tasks %>%
filter(Group == 0)
study2_cog_ASD <- study2_cog_tasks %>%
filter(Group == 1)
study2_cog_tasks <- study2_cog_tasks %>%
groupby(Subject) %>%
mutate(letter_count = mean(letter_1_count, letter_2_count),
semantic_count = mean(semantic_1_count, semantic_2_count))
study2_cog_tasks <- study2_cog_tasks %>%
group_by(Subject) %>%
mutate(letter_count = mean(letter_1_count, letter_2_count),
semantic_count = mean(semantic_1_count, semantic_2_count))
study2_cog_NTP <- study2_cog_tasks %>%
filter(Group == 0)
study2_cog_ASD <- study2_cog_tasks %>%
filter(Group == 1)
View(study2_cog_tasks)
?mean
study2_cog_tasks <- study2_cog_tasks %>%
group_by(Subject) %>%
mutate(letter_count = (letter_1_count + letter_2_count)/2,
semantic_count = (semantic_1_count + semantic_2_count)/2)
study2_cog_NTP <- study2_cog_tasks %>%
filter(Group == 0)
study2_cog_ASD <- study2_cog_tasks %>%
filter(Group == 1)
# letter fluency
shapiro.test(study2_cog_NTP$letter_count)
shapiro.test(study2_cog_ASD$letter_count)
mean(study2_cog_NTP$letter_count)
sd(study2_cog_NTP$letter_count)
mean(study2_cog_ASD$letter_count)
sd(study2_cog_ASD$letter_count)
wilcox.test(study2_cog_NTP$letter_count, study2_cog_ASD$letter_count)
wilcox_effsize(study2_cog_tasks, letter_count ~ Group)
# letter fluency
shapiro.test(study2_cog_NTP$letter_count)
shapiro.test(study2_cog_ASD$letter_count)
mean(study2_cog_NTP$letter_count)
sd(study2_cog_NTP$letter_count)
mean(study2_cog_ASD$letter_count)
sd(study2_cog_ASD$letter_count)
t.test(letter_count ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, letter_count ~ Group)
?cohens_d
# letter fluency
shapiro.test(study2_cog_NTP$letter_count)
shapiro.test(study2_cog_ASD$letter_count)
mean(study2_cog_NTP$letter_count)
sd(study2_cog_NTP$letter_count)
mean(study2_cog_ASD$letter_count)
sd(study2_cog_ASD$letter_count)
t.test(letter_count ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, letter_count ~ Group, var.equal = TRUE)
# letter fluency
shapiro.test(study2_cog_NTP$letter_count)
shapiro.test(study2_cog_ASD$letter_count)
mean(study2_cog_NTP$letter_count)
sd(study2_cog_NTP$letter_count)
mean(study2_cog_ASD$letter_count)
sd(study2_cog_ASD$letter_count)
t.test(letter_count ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, letter_count ~ Group, paired = FALSE)
library(tidyverse)
library(stats)
library(rstatix)
study1 <- read_delim("processed_data/study_1/data_study_1_general.csv", delim = ';')
study2 <- read_delim("processed_data/study_2/data_study_2_general.csv", delim = ';')
study2_cog_tasks <- read_csv("processed_data/study_2/data_study_2_cognitive_tasks.csv")
study1 <- study1 %>%
mutate(age = as.numeric(age))
study1_lowerAQ <- study1 %>%
filter(Group == 0)
study1_higherAQ <- study1 %>%
filter(Group == 1)
study2 <- study2 %>%
mutate(age = as.numeric(age))
study2_NTP <- study2 %>%
filter(Group == 0)
study2_ASD <- study2 %>%
filter(Group == 1)
mean(study1$age)
sd(study1$age)
shapiro.test(study1_lowerAQ$age)
shapiro.test(study1_higherAQ$age)
mean(study1_lowerAQ$age)
sd(study1_lowerAQ$age)
mean(study1_higherAQ$age)
sd(study1_higherAQ$age)
wilcox.test(study1_lowerAQ$age, study1_higherAQ$age)
wilcox_effsize(study1, age ~ Group)
shapiro.test(study2_cog_NTP$dspan)
shapiro.test(study2_cog_ASD$dspan)
mean(study2_cog_NTP$dspan)
sd(study2_cog_NTP$dspan)
mean(study2_cog_ASD$dspan)
sd(study2_cog_ASD$dspan)
t.test(dspan ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, dspan ~ Group)
cohens_d(study2_cog_tasks, letter_count ~ Group)
study2_cog_tasks <- study2_cog_tasks %>%
group_by(Subject) %>%
mutate(letter_count = (letter_1_count + letter_2_count)/2,
semantic_count = (semantic_1_count + semantic_2_count)/2)
study2_cog_NTP <- study2_cog_tasks %>%
filter(Group == 0)
study2_cog_ASD <- study2_cog_tasks %>%
filter(Group == 1)
# letter fluency
shapiro.test(study2_cog_NTP$letter_count)
shapiro.test(study2_cog_ASD$letter_count)
mean(study2_cog_NTP$letter_count)
sd(study2_cog_NTP$letter_count)
mean(study2_cog_ASD$letter_count)
sd(study2_cog_ASD$letter_count)
t.test(letter_count ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, letter_count ~ Group)
# semantic fluency
shapiro.test(study2_cog_NTP$semantic_count)
shapiro.test(study2_cog_ASD$semantic_count)
mean(study2_cog_NTP$semantic_count)
sd(study2_cog_NTP$semantic_count)
mean(study2_cog_ASD$semantic_count)
sd(study2_cog_ASD$semantic_count)
t.test(semantic_count ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, semantic_count ~ Group)
# semantic fluency
shapiro.test(study2_cog_NTP$semantic_count)
shapiro.test(study2_cog_ASD$semantic_count)
mean(study2_cog_NTP$semantic_count)
sd(study2_cog_NTP$semantic_count)
mean(study2_cog_ASD$semantic_count)
sd(study2_cog_ASD$semantic_count)
wilcos.test(study2_cog_NTP$semantic_count, study2_cog_ASD$semantic_count)
# semantic fluency
shapiro.test(study2_cog_NTP$semantic_count)
shapiro.test(study2_cog_ASD$semantic_count)
mean(study2_cog_NTP$semantic_count)
sd(study2_cog_NTP$semantic_count)
mean(study2_cog_ASD$semantic_count)
sd(study2_cog_ASD$semantic_count)
wilcox.test(study2_cog_NTP$semantic_count, study2_cog_ASD$semantic_count)
wilcox_effsize(study2_cog_tasks, semantic_count ~ Group)
library(tidyverse)
library(stats)
library(rstatix)
study1 <- read_delim("processed_data/study_1/data_study_1_general.csv", delim = ';')
study2 <- read_delim("processed_data/study_2/data_study_2_general.csv", delim = ';')
study2_cog_tasks <- read_csv("processed_data/study_2/data_study_2_cognitive_tasks.csv")
study1 <- study1 %>%
mutate(age = as.numeric(age))
study1_lowerAQ <- study1 %>%
filter(Group == 0)
study1_higherAQ <- study1 %>%
filter(Group == 1)
study2 <- study2 %>%
mutate(age = as.numeric(age))
study2_NTP <- study2 %>%
filter(Group == 0)
study2_ASD <- study2 %>%
filter(Group == 1)
mean(study1$age)
sd(study1$age)
shapiro.test(study1_lowerAQ$age)
shapiro.test(study1_higherAQ$age)
mean(study1_lowerAQ$age)
sd(study1_lowerAQ$age)
mean(study1_higherAQ$age)
sd(study1_higherAQ$age)
wilcox.test(study1_lowerAQ$age, study1_higherAQ$age)
wilcox_effsize(study1, age ~ Group)
table(study1$sex)
study1_sex_table = table(study1$Group, study1$sex)
study1_sex_table
chisq.test(study1_sex_table, correct = FALSE)
shapiro.test(study1_lowerAQ$digit_span)
shapiro.test(study1_higherAQ$digit_span)
mean(study1_lowerAQ$digit_span)
sd(study1_lowerAQ$digit_span)
mean(study1_higherAQ$digit_span)
sd(study1_higherAQ$digit_span)
wilcox.test(study1_lowerAQ$digit_span, study1_higherAQ$digit_span)
wilcox_effsize(study1, digit_span ~ Group)
shapiro.test(study2_NTP$age)
shapiro.test(study2_ASD$age)
mean(study2_NTP$age)
sd(study2_NTP$age)
mean(study2_ASD$age)
sd(study2_ASD$age)
wilcox.test(study2_NTP$age, study2_ASD$age)
wilcox_effsize(study2, age ~ Group)
study2_sex_table = table(study2$Group, study2$sex)
study2_sex_table
chisq.test(study2_sex_table, correct = FALSE)
study2_cog_tasks <- study2_cog_tasks %>%
group_by(Subject) %>%
mutate(letter_count = (letter_1_count + letter_2_count)/2,
semantic_count = (semantic_1_count + semantic_2_count)/2)
study2_cog_NTP <- study2_cog_tasks %>%
filter(Group == 0)
study2_cog_ASD <- study2_cog_tasks %>%
filter(Group == 1)
shapiro.test(study2_cog_NTP$dspan)
shapiro.test(study2_cog_ASD$dspan)
mean(study2_cog_NTP$dspan)
sd(study2_cog_NTP$dspan)
mean(study2_cog_ASD$dspan)
sd(study2_cog_ASD$dspan)
t.test(dspan ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, dspan ~ Group)
is.na(study2_cog_tasks$letter_count)
View(study2_cog_tasks)
library(tidyverse)
library(stats)
library(rstatix)
study1 <- read_delim("processed_data/study_1/data_study_1_general.csv", delim = ';')
study2 <- read_delim("processed_data/study_2/data_study_2_general.csv", delim = ';')
study2_cog_tasks <- read_csv("processed_data/study_2/data_study_2_cognitive_tasks.csv")
study1 <- study1 %>%
mutate(age = as.numeric(age))
study1_lowerAQ <- study1 %>%
filter(Group == 0)
study1_higherAQ <- study1 %>%
filter(Group == 1)
study2 <- study2 %>%
mutate(age = as.numeric(age))
study2_NTP <- study2 %>%
filter(Group == 0)
study2_ASD <- study2 %>%
filter(Group == 1)
mean(study1$age)
sd(study1$age)
shapiro.test(study1_lowerAQ$age)
shapiro.test(study1_higherAQ$age)
mean(study1_lowerAQ$age)
sd(study1_lowerAQ$age)
mean(study1_higherAQ$age)
sd(study1_higherAQ$age)
wilcox.test(study1_lowerAQ$age, study1_higherAQ$age)
wilcox_effsize(study1, age ~ Group)
table(study1$sex)
study1_sex_table = table(study1$Group, study1$sex)
study1_sex_table
chisq.test(study1_sex_table, correct = FALSE)
shapiro.test(study1_lowerAQ$digit_span)
shapiro.test(study1_higherAQ$digit_span)
mean(study1_lowerAQ$digit_span)
sd(study1_lowerAQ$digit_span)
mean(study1_higherAQ$digit_span)
sd(study1_higherAQ$digit_span)
wilcox.test(study1_lowerAQ$digit_span, study1_higherAQ$digit_span)
wilcox_effsize(study1, digit_span ~ Group)
shapiro.test(study2_NTP$age)
shapiro.test(study2_ASD$age)
mean(study2_NTP$age)
sd(study2_NTP$age)
mean(study2_ASD$age)
sd(study2_ASD$age)
wilcox.test(study2_NTP$age, study2_ASD$age)
wilcox_effsize(study2, age ~ Group)
study2_sex_table = table(study2$Group, study2$sex)
study2_sex_table
chisq.test(study2_sex_table, correct = FALSE)
study2_cog_tasks <- study2_cog_tasks %>%
group_by(Subject) %>%
mutate(letter_count = (letter_1_count + letter_2_count)/2,
semantic_count = (semantic_1_count + semantic_2_count)/2)
study2_cog_NTP <- study2_cog_tasks %>%
filter(Group == 0)
study2_cog_ASD <- study2_cog_tasks %>%
filter(Group == 1)
shapiro.test(study2_cog_NTP$dspan)
shapiro.test(study2_cog_ASD$dspan)
mean(study2_cog_NTP$dspan)
sd(study2_cog_NTP$dspan)
mean(study2_cog_ASD$dspan)
sd(study2_cog_ASD$dspan)
t.test(dspan ~ Group, data = study2_cog_tasks, var.equal = TRUE)
cohens_d(study2_cog_tasks, dspan ~ Group)
library(tidyverse)
library(ggplot2)
library(readxl)
library(psych)
library(plotrix)
library(lcmm)
library(nnet)
library(questionr)
set.seed(500)
study1_SL <- read_csv("processed_data/study_1/data_study_1_SL_offline_online.csv")
study1_VP <- read_csv("processed_data/study_1/data_study_1_VP_offline_online.csv")
study1_VP$ID <- seq.int(nrow(study1_VP))
study1_VP_numeric <- study1_VP %>%
select(c('AQ_total', 'block2_offline','block3_offline', 'block4_offline','block5_offline', 'block6_offline','block7_offline', 'block8_offline','block9_offline', 'block10_offline',
'block11_offline', 'block12_offline','block13_offline', 'block14_offline','block15_offline', 'block16_offline', 'block17_offline','block18_offline', 'block19_offline','block20_offline', 'block21_offline', 'block22_offline','block23_offline', 'block24_offline','block25_offline'))
# test normality
sapply(study1_VP_numeric, shapiro.test)
# make long data
study1_VP_long <- study1_VP %>%
select(c( 'ID', 'Group', 'AQ_total', 'Subject', 'block2_offline','block3_offline', 'block4_offline','block5_offline', 'block6_offline','block7_offline', 'block8_offline','block9_offline', 'block10_offline',
'block11_offline', 'block12_offline','block13_offline', 'block14_offline','block15_offline', 'block16_offline', 'block17_offline','block18_offline', 'block19_offline','block20_offline', 'block21_offline', 'block22_offline','block23_offline', 'block24_offline','block25_offline'))
blocks <- c('block2','block3', 'block4','block5', 'block6','block7', 'block8','block9', 'block10',
'block11', 'block12','block13', 'block14','block15', 'block16', 'block17','block18',
'block19','block20', 'block21', 'block22','block23', 'block24','block25')
study1_VP_long <- pivot_longer(
data = study1_VP_long,
cols = starts_with(blocks),
names_to = c("Block"),
values_to = "VP_score"
)
study1_VP_long <- study1_VP_long %>%
mutate(Block = gsub('_offline', "", Block)) %>%
mutate(Block = gsub('block', "", Block))
study1_VP_long <- study1_VP_long %>%
mutate(Block = as.numeric(Block)) %>%
mutate(Epoch = case_when(
between(Block, 2, 5)   ~ 1,
between(Block, 6, 10)  ~ 2,
between(Block, 11, 15) ~ 3,
between(Block, 16, 20) ~ 4,
between(Block, 21, 25) ~ 5
))
study1_VP_wide <- study1_VP_long %>%
group_by(ID, Subject, Group, AQ_total, Epoch) %>%
summarise(VP_score_epoch = median(VP_score, VP_score, na.rm = T)) %>%
ungroup()
m1.lin <- hlme(VP_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_VP_wide)
m2.lin <- gridsearch(hlme(VP_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_VP_wide, ng = 2, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
m3.lin <- gridsearch(hlme(VP_score_epoch ~ Epoch, random = ~Epoch, subject = 'ID', data = study1_VP_wide, ng = 3, mixture = ~Epoch), rep = 200, maxiter = 50, minit = m1.lin)
summarytable(m1.lin, m2.lin, m3.lin, which = c("G", "loglik", "conv", "npm", "AIC", "BIC", "SABIC", "entropy", "ICL", "%class"))
